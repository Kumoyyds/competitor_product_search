{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0769fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from llm_tools.llm_func import find_url_llm\n",
    "import yaml\n",
    "from llm_tools.other_func import get_split_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b35b5",
   "metadata": {},
   "source": [
    "# Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45483427",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f320afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "input_file_name = config['input_file']\n",
    "input_path = os.path.join(os.getcwd(), f\"input/{input_file_name}\")\n",
    "file = pd.read_excel(input_path)\n",
    "\n",
    "# output path \n",
    "output_path = config['output_file']\n",
    "output_path = os.path.join(os.getcwd(), f\"output/{output_path}\")\n",
    "\n",
    "# output_partition path\n",
    "output_p_root = os.path.join(os.getcwd(), \"output/output_partitions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f9890",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5809d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_match = config.get('use_match', None)\n",
    "if use_match not in [0, 1]:\n",
    "    raise ValueError(\"Please set the use_match parameter to 0 or 1 in the config.yaml file.\")\n",
    "\n",
    "\n",
    "match_file_path = config.get('match_file', None)\n",
    "if use_match==1 and not match_file_path:\n",
    "    raise ValueError(\"Please provide the match_file in the config.yaml file if using match.\")\n",
    "\n",
    "if use_match:\n",
    "    match_file_path = os.path.join(os.getcwd(), f\"input/{match_file_path}\")\n",
    "    match_file = pd.read_excel(match_file_path)\n",
    "    # make sure the category and web col name unified as well \n",
    "    web_col = config.get('match_web_col', None)\n",
    "    cate_col = config.get('match_cate_col', None)\n",
    "    if not web_col or not cate_col:\n",
    "        raise ValueError(\"Please provide the match_web_col and match_cate_col in the config.yaml file if using match.\")\n",
    "    match_file.rename(columns={web_col: 'web', cate_col: 'Category'}, inplace=True)\n",
    "    match_file['Category'] = match_file['Category'].apply(lambda x: x.strip())\n",
    "    # the cate used to do match should be defined as well \n",
    "\n",
    "    match_dict = {}\n",
    "    for i in range(match_file.shape[0]):\n",
    "        match_dict[match_file.iloc[i, 0]] = list(match_file.iloc[i, 1:])\n",
    "\n",
    "else:\n",
    "    # be in the yaml\n",
    "    web = config.get('web', None)\n",
    "    if not web:\n",
    "        raise ValueError(\"Please provide the web name in the config.yaml file if not using match.\")\n",
    "\n",
    "    file['web_1'] = web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56caab",
   "metadata": {},
   "source": [
    "# matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be639a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_match:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    def embedding_one(text):\n",
    "        return model.encode(text)\n",
    "# the categories associated with files\n",
    "    file_cate = config.get('input_cate_col', None)\n",
    "    if not file_cate:\n",
    "        raise ValueError(\"Please provide the input_cate_col in the config.yaml file if using match.\")\n",
    "    file.rename(columns={file_cate: 'suggest_cate_1'}, inplace=True)\n",
    "    file_embedding = {}\n",
    "    for i in tqdm(set(file['suggest_cate_1']), total=len(set(file['suggest_cate_1']))):\n",
    "        file_embedding[i] = embedding_one(i)\n",
    "\n",
    "# the categories associated with the web\n",
    "    cate_embedding = {}\n",
    "    for i in tqdm(match_dict, total=len(match_dict)):\n",
    "        cate_embedding[i] = embedding_one(i)\n",
    "    cate_list = [i for i in match_dict]\n",
    "    cate_matrix = np.vstack([cate_embedding[i] for i in cate_list])\n",
    "\n",
    "    file.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cate_col = 'suggest_cate_1'\n",
    "    n_web = len(match_dict[list(match_dict.keys())[0]])\n",
    "\n",
    "    results = [[] for i in range(n_web)]\n",
    "    match_c = []\n",
    "    sim_v = []\n",
    "    for i in range(file.shape[0]):\n",
    "        v = file_embedding[file.loc[i, cate_col]]\n",
    "    # the similarity\n",
    "    sim = cate_matrix @ v\n",
    "\n",
    "    # max similarity\n",
    "    sim_max_i = np.argmax(sim)\n",
    "\n",
    "    # matched_cate\n",
    "    c = cate_list[sim_max_i]\n",
    "\n",
    "    sim_v.append(sim[sim_max_i])\n",
    "\n",
    "    match_c.append(c)\n",
    "    item = match_dict[c]\n",
    "    for j in range(n_web):\n",
    "        results[j].append(item[j])\n",
    "\n",
    "    file['match_c'] = match_c\n",
    "    file['sim'] = sim_v\n",
    "    for i in range(n_web):\n",
    "        file[f\"web_{i+1}\"] = results[i]   \n",
    "\n",
    "\n",
    "    ### setting in yaml\n",
    "    sim_cri = config.get('sim_cri', 0.5)\n",
    "    mask = (file['sim']>sim_cri) \n",
    "    # done\n",
    "    file = file.loc[mask]\n",
    "    file.reset_index(drop=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090418e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = config.get('input_sku_name_col', None)\n",
    "country = config.get('country', None)\n",
    "\n",
    "if not name_col or not country:\n",
    "    raise ValueError(\"Please provide the input_sku_name_col and country in the config.yaml file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4977c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### yaml definition\n",
    "def find_the_url(df):\n",
    "  df = find_url_llm(df, name_col=name_col, web_col='web_1', country=country, url_col_name='url_search_1')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71ecf5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yudingduan/Documents/JD/programming/retail_agents/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1 begins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 3/60 [00:13<04:17,  4.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m dfs = files[i*chunk:(i+\u001b[32m1\u001b[39m)*chunk]\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m concurrent.futures.ThreadPoolExecutor(max_workers=\u001b[32m16\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m   dfs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_the_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m df = pd.concat(dfs, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     13\u001b[39m df.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JD/programming/retail_agents/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "split_num = get_split_num(file.shape[0])\n",
    "files = np.array_split(file, split_num)\n",
    "\n",
    "\n",
    "round = split_num//1000 + 1\n",
    "chunk = int(split_num/round)\n",
    "for i in range(round):\n",
    "  print(f\"round {i+1} begins\")\n",
    "  dfs = files[i*chunk:(i+1)*chunk]\n",
    "  with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    dfs = list(tqdm(executor.map(find_the_url, dfs), total=chunk))\n",
    "  df = pd.concat(dfs, axis=0)\n",
    "  df.reset_index(drop=True, inplace=True)\n",
    "  # after 30000, use 2\n",
    "  df.to_excel(output_p_root+f'/result_{i}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e6952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16f19986",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = config.get('output_file', None)\n",
    "if not output_file_name:\n",
    "    raise ValueError(\"Please provide the output_file in the config.yaml file.\")\n",
    "\n",
    "output_result_path = os.path.join(os.getcwd(), f\"output/{output_file_name}\")\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for i in range(round):\n",
    "  df = pd.read_excel(output_p_root+f'result_{i}.xlsx')\n",
    "  dfs.append(df)\n",
    "dfs = pd.concat(dfs, axis=0)\n",
    "dfs.reset_index(drop=True, inplace=True)\n",
    "dfs.to_excel(output_result_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
