{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import re\n",
    "from llm_tools.llm_func import do_product_searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b35b5",
   "metadata": {},
   "source": [
    "# Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f320afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "input_path = os.path.join(os.getcwd(), \"input/amazon_de_url.xlsx\")\n",
    "\n",
    "file = pd.read_excel(input_path)\n",
    "\n",
    "# output path \n",
    "output_path = 'result.xlsx'\n",
    "output_path = os.path.join(os.getcwd(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f9890",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_match = 0\n",
    "\n",
    "\n",
    "match_file_path = 'match_file'\n",
    "\n",
    "if use_match:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    match_file_path = os.path.join(os.getcwd(), match_file_path)\n",
    "    match_file = pd.read_excel(match_file_path)\n",
    "    # make sure the category and web col name unified as well \n",
    "    match_file['Category'] = match_file['Category'].apply(lambda x: x.strip())\n",
    "    # the cate used to do match should be defined as well \n",
    "\n",
    "    match_dict = {}\n",
    "    for i in range(match_file.shape[0]):\n",
    "        match_dict[match_file.iloc[i, 0]] = list(match_file.iloc[i, 1:])\n",
    "\n",
    "else:\n",
    "    # be in the yaml\n",
    "    web = web\n",
    "    \n",
    "    file['web_1'] = web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56caab",
   "metadata": {},
   "source": [
    "# matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be639a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_match:\n",
    "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    def embedding_one(text):\n",
    "        return model.encode(text)\n",
    "# the categories associated with files\n",
    "    file_embedding = {}\n",
    "    for i in tqdm(set(file['suggest_cate_1']), total=len(set(file['suggest_cate_1']))):\n",
    "        file_embedding[i] = embedding_one(i)\n",
    "\n",
    "# the categories associated with the web\n",
    "    cate_embedding = {}\n",
    "    for i in tqdm(match_dict, total=len(match_dict)):\n",
    "        cate_embedding[i] = embedding_one(i)\n",
    "    cate_list = [i for i in match_dict]\n",
    "    cate_matrix = np.vstack([cate_embedding[i] for i in cate_list])\n",
    "\n",
    "    file.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cate_col = 'suggest_cate_1'\n",
    "    n_web = len(match_dict[list(match_dict.keys())[0]])\n",
    "\n",
    "    results = [[] for i in range(n_web)]\n",
    "    match_c = []\n",
    "    sim_v = []\n",
    "    for i in range(file.shape[0]):\n",
    "        v = file_embedding[file.loc[i, cate_col]]\n",
    "    # the similarity\n",
    "    sim = cate_matrix @ v\n",
    "\n",
    "    # max similarity\n",
    "    sim_max_i = np.argmax(sim)\n",
    "\n",
    "    # matched_cate\n",
    "    c = cate_list[sim_max_i]\n",
    "\n",
    "    sim_v.append(sim[sim_max_i])\n",
    "\n",
    "    match_c.append(c)\n",
    "    item = match_dict[c]\n",
    "    for j in range(n_web):\n",
    "        results[j].append(item[j])\n",
    "\n",
    "    file['match_c'] = match_c\n",
    "    file['sim'] = sim_v\n",
    "    for i in range(n_web):\n",
    "        file[f\"web_{i+1}\"] = results[i]   \n",
    "\n",
    "\n",
    "    ### setting in yaml\n",
    "    sim_cri = sim_cri\n",
    "    mask = (file['sim']>sim_cri) \n",
    "    # done\n",
    "    file = file.loc[mask]\n",
    "    file.reset_index(drop=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### yaml definition\n",
    "def find_the_url(df, name_col=name_col, web_col='web_1', country=country, url_col_name=url_col_name):\n",
    "#def find_the_url(df, name_col='item_sku_name_en', web_col='web_1', country='uk', url_col_name='url_search_1'):\n",
    "  result = []\n",
    "  df.reset_index(drop=True, inplace=True)\n",
    "  for i in range(df.shape[0]):\n",
    "    product_name = df.loc[i, name_col]\n",
    "    mkt_plc = df.loc[i, web_col]\n",
    "    r = do_product_searching(product_name, mkt_plc, country=country)\n",
    "    result.append(r)\n",
    "  df[url_col_name] = result\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
